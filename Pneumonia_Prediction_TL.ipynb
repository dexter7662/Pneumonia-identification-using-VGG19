{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumonia Prediction TL",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/TCrL67NbhThJN6ke1DVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dexter7662/Pneumonia-identification-using-VGG19/blob/main/Pneumonia_Prediction_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZzuSsISi6ML"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EVdrSEgE_CX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgAtY378GBWO"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"lorddexter\"\n",
        "os.environ['KAGGLE_KEY'] = \"281706d18d96f899cdc0f5617516c67a\"\n",
        "!kaggle datasets download -d khoongweihao/covid19-xray-dataset-train-test-sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dml6WNFuGCKw"
      },
      "source": [
        "!unzip covid19-xray-dataset-train-test-sets.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmKobIvXi_R5"
      },
      "source": [
        "Creating the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEG3lhXGGgm"
      },
      "source": [
        "main = 'xray_dataset_covid19/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSmWvj2cGJIH"
      },
      "source": [
        "train_normal = os.listdir(main + 'train/NORMAL')\n",
        "train_pneumonia = os.listdir(main + 'train/PNEUMONIA')\n",
        "\n",
        "test_normal = os.listdir(main + 'test/NORMAL')\n",
        "test_pneumonia = os.listdir(main + 'test/PNEUMONIA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYTIvWOjGMRF"
      },
      "source": [
        "def dataframe(filenames, classes):\n",
        "  return pd.DataFrame({'Filename': filenames, 'Label': [classes]*len(filenames)})\n",
        "\n",
        "train_normal_df = dataframe(train_normal, 'Normal')\n",
        "train_pneumonia_df = dataframe(train_pneumonia, 'Pneumonia')\n",
        "\n",
        "test_normal_df = dataframe(test_normal, 'Normal')\n",
        "test_pneumonia_df = dataframe(test_pneumonia, 'Pneumonia')\n",
        "\n",
        "train_df = pd.concat([train_normal_df, train_pneumonia_df], axis=0)\n",
        "test_df = pd.concat([test_normal_df, test_pneumonia_df], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLQN2z_lGQwD"
      },
      "source": [
        "def pathmaker(df_name, df, empty_list):\n",
        "    for i in df_name.values:\n",
        "        if i[1] == 'Normal':\n",
        "            empty_list.append(str(main + df + '/NORMAL/'+i[0]))\n",
        "        else:\n",
        "            empty_list.append(str(main + df + '/PNEUMONIA/'+i[0]))\n",
        "\n",
        "\n",
        "#Empty list to be passed in path maker\n",
        "train_path = []\n",
        "test_path = []\n",
        "\n",
        "#Assigning Path maker\n",
        "pathmaker(train_df, 'train', train_path)\n",
        "pathmaker(test_df, 'test', test_path)\n",
        "\n",
        "train_df['Path'] = train_path\n",
        "test_df['Path'] = test_path\n",
        "\n",
        "#Shuffling / Re-arranging rows\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True).iloc[:, 1:]\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True).iloc[:, 1:]\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pgfnVwYjC1v"
      },
      "source": [
        "Checking for data imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzTT0SxQGVGB"
      },
      "source": [
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.countplot(x='Label', data=train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7KmyppyGdOx"
      },
      "source": [
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.countplot(x='Label', data=test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahKRONFKjGTf"
      },
      "source": [
        "Dataset splitting into training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxjePL1MGgcl"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulfGe1xP6emb"
      },
      "source": [
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=None,\n",
        "    x_col='Path',\n",
        "    y_col='Label',\n",
        "    subset='training',\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    validate_filenames=False\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=None,\n",
        "    x_col='Path',\n",
        "    y_col='Label',\n",
        "    subset='validation',\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    validate_filenames=False\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=None,\n",
        "    x_col='Path',\n",
        "    y_col=None,\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    target_size=(224, 224),\n",
        "    validate_filenames=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3jQRPhljNAq"
      },
      "source": [
        "Importing the VGG-16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O9LtL3_GoFA"
      },
      "source": [
        "vgg = VGG16(include_top=False, weights='imagenet', input_shape=[224,224,3])\n",
        "vgg.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgWzRsPwH3_f"
      },
      "source": [
        "x = Flatten()(vgg.output)\n",
        "dense1 = Dense(units=4096,activation='relu', kernel_regularizer= l2(0.0005), kernel_initializer= 'random_normal', bias_initializer= 'zeros')(x)\n",
        "dropout1 = Dropout(rate=0.5)(dense1)\n",
        "dense2 = Dense(units=4096, activation='relu', kernel_regularizer= l2(0.0005), kernel_initializer= 'random_normal', bias_initializer= 'zeros')(dropout1)\n",
        "dropout2 = Dropout(rate=0.5)(dense2)\n",
        "output = Dense(units=2, activation='sigmoid', kernel_regularizer= l2(0.0005), kernel_initializer= 'random_normal', bias_initializer= 'zeros')(dropout2)\n",
        "A = Model(inputs = vgg.input, outputs = output)\n",
        "A.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxU5c3GUIndp"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
        "A.compile(optimizer= opt, metrics=['accuracy'], loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1sNGvXaIrmZ"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('accuracy') >= 0.9):\n",
        "      print('\\nReached 90% accuracy so cancelling training!')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "myCallback_object = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w75djC29IvG0"
      },
      "source": [
        "model = A.fit(x=train_generator, validation_data= validation_generator, epochs=25, callbacks=myCallback_object, batch_size=148)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ezPCYPrjSth"
      },
      "source": [
        "Testing the model on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDUynBn-LNMC"
      },
      "source": [
        "test_generator.reset()\n",
        "y_pred = A.predict(test_generator)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zmlKMNALaWK"
      },
      "source": [
        "predicted_class_indices=np.argmax(y_pred,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PrPJp5hLevO"
      },
      "source": [
        "names = (train_generator.class_indices)\n",
        "names = dict((v,k) for k,v in names.items())\n",
        "predictions = [names[k] for k in predicted_class_indices]\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmIaTer7jXfQ"
      },
      "source": [
        "Checking for accuracy, recall, precision and f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIANvdILiMh"
      },
      "source": [
        "sns.heatmap(confusion_matrix(test_df['Label'], predictions), annot=True, cmap='inferno_r', square=True)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrs_cMrDLlpQ"
      },
      "source": [
        "accuracy = accuracy_score(test_df['Label'], predictions)\n",
        "print(accuracy)\n",
        "\n",
        "precision = precision_score(test_df['Label'], predictions, average='micro')\n",
        "print(precision)\n",
        "\n",
        "\n",
        "recall = recall_score(test_df['Label'], predictions, average='micro')\n",
        "print(recall)\n",
        "\n",
        "f1 = f1_score(test_df['Label'], predictions, average='micro')\n",
        "print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}